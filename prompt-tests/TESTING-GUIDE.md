# WaveMaker ReAct Agent - Automated Testing Guide

Complete guide for running automated tests with OpenAI + MCP.

## ğŸš€ Quick Start

```bash
# 1. Install dependencies
cd /Users/raajr_500278/ai/wavemaker-rn-mcp/prompt-tests
npm install

# 2. Set API key
export OPENAI_API_KEY=sk-...

# 3. Build MCP server (if not already built)
cd ..
npm run build

# 4. Run test
cd prompt-tests
node test-runner.js --test 1.1
```

## ğŸ“‹ Prerequisites

### 1. OpenAI API Key

Get your API key: https://platform.openai.com/api-keys

```bash
export OPENAI_API_KEY=sk-...
```

**Recommended Models:**
- `gpt-4o` - Best instruction following (recommended)
- `gpt-4-turbo` - Fast, excellent quality
- `gpt-3.5-turbo` - Budget option

### 2. MCP Server Built

```bash
cd /Users/raajr_500278/ai/wavemaker-rn-mcp
npm run build
```

### 3. Dependencies Installed

```bash
cd prompt-tests
npm install
```

Required packages:
- `openai` - Official OpenAI SDK
- `@modelcontextprotocol/sdk` - MCP client

## ğŸ§ª Running Tests

### Single Test

```bash
node test-runner.js --test 1.1
```

### Example Output

```bash
ğŸ§ª Running Test 1.1

ğŸ“¡ Connecting to MCP server...
âœ… Connected to MCP server

Query: How do I use the Button widget?

Loaded 50 MCP tools

  Iteration 1
    ğŸš« BLOCK: Providing paths
  Iteration 2
    ğŸ”§ 1 tool(s) called
       â†’ search_widget_by_name
  Iteration 3
    ğŸ”§ 1 tool(s) called
       â†’ read_widget_structure
  Iteration 4
    âœ… COMPLETE

ğŸ“ Saved actual output: actual/1.1-run-1733845678901.json

ğŸ” Validating Agent Response

1. Tool Selection
  âœ… Tool called: search_widget_by_name
  âœ… Tool called: read_widget_structure

2. Data Accuracy
  âœ… All 17 props documented
  âœ… All 1 events documented
  âœ… Key style classes documented

3. Completeness
  âœ… Props table present
  âœ… Events section present
  âœ… Style section present
  âœ… 3 code examples provided
  âœ… Evidence trail present

4. Answer Quality
  âœ… Answer is actionable
  âœ… Code examples are runnable
  âœ… Well-structured answer (5 sections)

5. Context Management
  âœ… Session context tracked
  âœ… Task context tracked
  âœ… Correct decision flow

============================================================
âœ… Test 1.1: 95/100 points
============================================================

Category Breakdown:

  toolSelection        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 20/20
  dataAccuracy         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 30/30
  completeness         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘ 23/25
  answerQuality        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘ 13/15
  contextManagement    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 9/10

Issues Found:
  âš ï¸  Missing 1 code example (expected 4, got 3)
  âš ï¸  Missing task context key: widgetFiles

ğŸ‘‹ Disconnected from MCP
```

## ğŸ“Š How It Works

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ test-runner â”‚ â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                  â”‚  1. Load WM_PROMPT.md
                  â”‚  2. Connect to MCP
                  â”‚  3. Initialize Gemini
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   Gemini    â”‚ â†â”€â”˜
â”‚  API (AI)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ 4. Generate with tools
       â”‚ 5. Call functions
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MCP Server  â”‚ â”€â”€â†’ 50+ Tools
â”‚ (wavemaker) â”‚     (search, read, analyze)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ 6. Return results
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Capture    â”‚ â”€â”€â†’ actual/1.1-run.json
â”‚  Output     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ 7. Validate
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Validator  â”‚ â”€â”€â†’ Compare with expected
â”‚             â”‚     Score: 95/100
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flow

1. **Load Test**: Read `expected/1.1-button-widget.json`
2. **Connect MCP**: Start MCP server, get 50+ tools
3. **Initialize Gemini**: Load WM_PROMPT.md as system instruction
4. **Agent Loop**:
   - Gemini generates response (THOUGHT â†’ ACTION)
   - If function calls â†’ Execute via MCP â†’ Return results
   - If BLOCK â†’ Provide paths automatically
   - If COMPLETE â†’ Extract answer
5. **Capture**: Save tool calls, decisions, working memory, answer
6. **Validate**: Compare actual vs expected, calculate score

## ğŸ”§ Gemini API Details

### Model

```javascript
model: 'gemini-2.0-flash-exp'
```

- Best for function calling
- Fast and cost-efficient
- 1M token context window

Reference: https://ai.google.dev/gemini-api/docs#javascript

### Configuration

```javascript
const config = {
  systemInstruction: WM_PROMPT.md,  // ReAct pattern
  temperature: 0.7,                  // Balanced creativity
  tools: [{ functionDeclarations }]  // MCP tools
};
```

### Multi-turn Conversation

```javascript
const contents = [
  { role: 'user', parts: [{ text: 'Query' }] },
  { role: 'model', parts: [{ functionCall }] },
  { role: 'user', parts: [{ functionResponse }] },
  ...
];
```

### Function Calling

```javascript
// Gemini calls function
chunk.functionCalls[0] = {
  name: 'search_widget_by_name',
  args: { widgetName: 'Button', ... }
}

// Execute via MCP
const result = await mcpClient.callTool({
  name: call.name,
  arguments: call.args
});

// Return to Gemini
{ 
  role: 'user',
  parts: [{
    functionResponse: {
      name: call.name,
      response: { result }
    }
  }]
}
```

## ğŸ“ File Structure

```
prompt-tests/
â”œâ”€â”€ test-runner.js          # Main runner (Gemini + MCP)
â”œâ”€â”€ validator.js            # Validator (compares JSON)
â”œâ”€â”€ package.json            # Dependencies
â”‚
â”œâ”€â”€ expected/               # Ground truth
â”‚   â””â”€â”€ 1.1-button-widget.json
â”‚
â”œâ”€â”€ actual/                 # Captured outputs
â”‚   â””â”€â”€ 1.1-run-<timestamp>.json
â”‚
â””â”€â”€ test-scenarios/         # Test queries
    â””â”€â”€ 01-widget-discovery.txt
```

## ğŸ¯ Expected JSON Format

```json
{
  "testId": "1.1",
  "query": "How do I use the Button widget?",
  "paths": {
    "runtimePath": "/path/to/runtime",
    "codegenPath": "/path/to/codegen"
  },
  "groundTruth": {
    "props": { "total": 17, "list": [...] },
    "events": { "total": 1, "list": [...] },
    "styles": { "parts": [...], "classes": [...] }
  },
  "expectedAnswer": {
    "mustDocument": {
      "criticalProps": ["caption", "onTap", ...],
      ...
    }
  }
}
```

## ğŸ› Troubleshooting

### "GEMINI_API_KEY not set"

```bash
export GEMINI_API_KEY=AIzaSy...
# Get key: https://aistudio.google.com/apikey
```

### "MCP server not found"

```bash
# Build MCP server first
cd /Users/raajr_500278/ai/wavemaker-rn-mcp
npm run build
```

### "Cannot find module @google/genai"

```bash
cd prompt-tests
npm install
```

### "Test failed with low score"

Check validation output:
```bash
cat actual/1.1-run-<timestamp>.json
```

Common issues:
- Missing props in answer
- Wrong tools called
- Context not tracked
- Hallucinated data (props that don't exist)

## ğŸ“ˆ Scoring

| Category | Points | What's Validated |
|----------|--------|------------------|
| Tool Selection | 20 | Correct tools in correct order |
| Data Accuracy | 30 | Props match codebase, no hallucinations |
| Completeness | 25 | All required sections present |
| Answer Quality | 15 | Actionable, runnable examples |
| Context Management | 10 | Session/task context tracked, correct decisions |

**Pass:** 75/100

## ğŸš€ Next Steps

1. âœ… Test 1.1 passing â†’ Create Test 1.2
2. âœ… All Widget tests passing â†’ Create styling tests
3. âœ… All tests passing â†’ CI/CD integration
4. ğŸ¯ Regression testing before prompt changes

## ğŸ”— References

- Gemini API Docs: https://ai.google.dev/gemini-api/docs#javascript
- Get API Key: https://aistudio.google.com/apikey
- MCP SDK: https://github.com/modelcontextprotocol/sdk
- WaveMaker MCP: /Users/raajr_500278/ai/wavemaker-rn-mcp

